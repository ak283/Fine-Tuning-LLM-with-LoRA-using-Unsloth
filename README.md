# Fine-Tuning-LLM-with-LoRA-using-Unsloth
Tools: Python, Unsloth, Lora, PEFT, Quantization, Pytorch, LLaMA 3  

•	Fine-tuned Meta’s LLaMA 3–8B model on a custom instruction-response dataset using Unsloth with LoRA (Low-Rank Adaptation) for efficient training.  
•	Applied PEFT techniques to adapt only a small number of model parameters, reducing training cost while maintaining output quality.  
•	Built a high-quality dataset with structured prompts to align the model.  
